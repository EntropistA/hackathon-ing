{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_input_data_eng.csv\").fillna(\"\")  # maybe drop?\n",
    "print(df.shape[0])\n",
    "\n",
    "x_columns = \"text\"\n",
    "y_columns = \"label_id\"\n",
    "x, y = df[x_columns], df[y_columns]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=4, stratify=y)\n",
    "\n",
    "training = pd.concat([x_train, y_train], axis=1)\n",
    "testing = pd.concat([x_test, y_test], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  label_id\n39                                                              3\n6956  invoice march nob tobacco industry national co...         1\n1953  political camfaign contribution request date f...         1\n3862  ace tlg lotresults fepdet crof verr tark esx p...        16\n1833  rjr s june sefeet nobyl dcclassi fi-afian to h...         7\n...                                                 ...       ...\n2122  ealshedeilier rqdrescrlellye hanufacturing cer...        17\n3934  newman-stein inc broadway job new york ny augu...        13\n6669  mar from slper arketing inc rjrpronotions clie...         6\n8931  principal investigatoaprogran dikecidy arthur ...        14\n6888        huduall yes lxd saga n kips meriuz bit luux         7\n\n[6760 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6956</th>\n      <td>invoice march nob tobacco industry national co...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1953</th>\n      <td>political camfaign contribution request date f...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3862</th>\n      <td>ace tlg lotresults fepdet crof verr tark esx p...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1833</th>\n      <td>rjr s june sefeet nobyl dcclassi fi-afian to h...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2122</th>\n      <td>ealshedeilier rqdrescrlellye hanufacturing cer...</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3934</th>\n      <td>newman-stein inc broadway job new york ny augu...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>6669</th>\n      <td>mar from slper arketing inc rjrpronotions clie...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8931</th>\n      <td>principal investigatoaprogran dikecidy arthur ...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6888</th>\n      <td>huduall yes lxd saga n kips meriuz bit luux</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>6760 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  label_id\n7453  sorillard memorandum max to mr goldbrenner fro...         8\n6972  e n w h mhl k hh m l j ul n m l a ve g w ie h ...         6\n1832  kantuety joumel o commets wanegrom dstt l tx g...         9\n6385  auz leon g cooperman chairman omege advisors i...        14\n7117                                      i h ie gglz l         9\n...                                                 ...       ...\n8833  clealtk qec sacramento bee weds smoking and vi...         9\n2276                                                            3\n8088  borriston laboratories inc sponsor lorillard i...        16\n1946  biographical sketch nane romaine r bruns posit...        14\n1522  jndinai ljs froms ostem erc sent moncdy june p...         2\n\n[2254 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7453</th>\n      <td>sorillard memorandum max to mr goldbrenner fro...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6972</th>\n      <td>e n w h mhl k hh m l j ul n m l a ve g w ie h ...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>kantuety joumel o commets wanegrom dstt l tx g...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6385</th>\n      <td>auz leon g cooperman chairman omege advisors i...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7117</th>\n      <td>i h ie gglz l</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8833</th>\n      <td>clealtk qec sacramento bee weds smoking and vi...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8088</th>\n      <td>borriston laboratories inc sponsor lorillard i...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1946</th>\n      <td>biographical sketch nane romaine r bruns posit...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1522</th>\n      <td>jndinai ljs froms ostem erc sent moncdy june p...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2254 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sentences = x_train.to_list()\n",
    "\n",
    "LABEL_N = 21\n",
    "\n",
    "# First approach\n",
    "# LEARNING_RATE = 0.01\n",
    "# VOCAB_SIZE = 10_000\n",
    "# EMBEDDING_DIM = 16\n",
    "# DENSE_LAYER_COUNT = 128\n",
    "# max_length = 600\n",
    "# trunc_type='post'\n",
    "# padding_type='post'\n",
    "\n",
    "def pad(sequences):\n",
    "    return pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Optimized\n",
    "LEARNING_RATE = 0.002\n",
    "VOCAB_SIZE = 2_000\n",
    "EMBEDDING_DIM = 64\n",
    "DENSE_LAYER_COUNT = 128\n",
    "max_length = 400\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad(training_sequences)\n",
    "# training_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "testing_sentences = x_test.to_list()\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad(testing_sequences)\n",
    "# testing_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_all_categories_columns(input_array: np.array):\n",
    "    result = np.zeros(shape=(input_array.shape[0], LABEL_N), dtype=int)\n",
    "    result[np.arange(0, input_array.shape[0]), input_array] = 1\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = create_all_categories_columns(np.array(y_train))\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = create_all_categories_columns(np.array(y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          128000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                2709      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,029\n",
      "Trainable params: 139,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(DENSE_LAYER_COUNT, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(LABEL_N, activation='softmax'),\n",
    "])\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "212/212 - 2s - loss: 2.5438 - accuracy: 0.1766 - val_loss: 2.3573 - val_accuracy: 0.2449 - 2s/epoch - 11ms/step\n",
      "Epoch 2/25\n",
      "212/212 - 1s - loss: 2.1735 - accuracy: 0.3047 - val_loss: 2.0450 - val_accuracy: 0.3492 - 1s/epoch - 5ms/step\n",
      "Epoch 3/25\n",
      "212/212 - 1s - loss: 1.8892 - accuracy: 0.3970 - val_loss: 1.8030 - val_accuracy: 0.4401 - 986ms/epoch - 5ms/step\n",
      "Epoch 4/25\n",
      "212/212 - 1s - loss: 1.6661 - accuracy: 0.4857 - val_loss: 1.6635 - val_accuracy: 0.4698 - 990ms/epoch - 5ms/step\n",
      "Epoch 5/25\n",
      "212/212 - 1s - loss: 1.4958 - accuracy: 0.5370 - val_loss: 1.5268 - val_accuracy: 0.5271 - 1s/epoch - 5ms/step\n",
      "Epoch 6/25\n",
      "212/212 - 1s - loss: 1.3577 - accuracy: 0.5861 - val_loss: 1.4464 - val_accuracy: 0.5497 - 974ms/epoch - 5ms/step\n",
      "Epoch 7/25\n",
      "212/212 - 1s - loss: 1.2504 - accuracy: 0.6163 - val_loss: 1.4034 - val_accuracy: 0.5630 - 1s/epoch - 5ms/step\n",
      "Epoch 8/25\n",
      "212/212 - 1s - loss: 1.1669 - accuracy: 0.6447 - val_loss: 1.3745 - val_accuracy: 0.6127 - 976ms/epoch - 5ms/step\n",
      "Epoch 9/25\n",
      "212/212 - 2s - loss: 1.0830 - accuracy: 0.6759 - val_loss: 1.3111 - val_accuracy: 0.6025 - 2s/epoch - 7ms/step\n",
      "Epoch 10/25\n",
      "212/212 - 1s - loss: 1.0213 - accuracy: 0.6945 - val_loss: 1.3237 - val_accuracy: 0.5878 - 1s/epoch - 6ms/step\n",
      "Epoch 11/25\n",
      "212/212 - 1s - loss: 0.9670 - accuracy: 0.7071 - val_loss: 1.2787 - val_accuracy: 0.6256 - 1s/epoch - 5ms/step\n",
      "Epoch 12/25\n",
      "212/212 - 1s - loss: 0.9144 - accuracy: 0.7263 - val_loss: 1.3108 - val_accuracy: 0.6158 - 1s/epoch - 5ms/step\n",
      "Epoch 13/25\n",
      "212/212 - 1s - loss: 0.8741 - accuracy: 0.7422 - val_loss: 1.2933 - val_accuracy: 0.6327 - 995ms/epoch - 5ms/step\n",
      "Epoch 14/25\n",
      "212/212 - 1s - loss: 0.8341 - accuracy: 0.7604 - val_loss: 1.2712 - val_accuracy: 0.6353 - 974ms/epoch - 5ms/step\n",
      "Epoch 15/25\n",
      "212/212 - 1s - loss: 0.7943 - accuracy: 0.7738 - val_loss: 1.2802 - val_accuracy: 0.6442 - 972ms/epoch - 5ms/step\n",
      "Epoch 16/25\n",
      "212/212 - 1s - loss: 0.7576 - accuracy: 0.7849 - val_loss: 1.3145 - val_accuracy: 0.6358 - 969ms/epoch - 5ms/step\n",
      "Epoch 17/25\n",
      "212/212 - 1s - loss: 0.7333 - accuracy: 0.7880 - val_loss: 1.3090 - val_accuracy: 0.6429 - 965ms/epoch - 5ms/step\n",
      "Epoch 18/25\n",
      "212/212 - 1s - loss: 0.6941 - accuracy: 0.7994 - val_loss: 1.3356 - val_accuracy: 0.6393 - 964ms/epoch - 5ms/step\n",
      "Epoch 19/25\n",
      "212/212 - 1s - loss: 0.6778 - accuracy: 0.8056 - val_loss: 1.3330 - val_accuracy: 0.6504 - 968ms/epoch - 5ms/step\n",
      "Epoch 20/25\n",
      "212/212 - 1s - loss: 0.6485 - accuracy: 0.8157 - val_loss: 1.3700 - val_accuracy: 0.6393 - 978ms/epoch - 5ms/step\n",
      "Epoch 21/25\n",
      "212/212 - 1s - loss: 0.6341 - accuracy: 0.8198 - val_loss: 1.3953 - val_accuracy: 0.6433 - 975ms/epoch - 5ms/step\n",
      "Epoch 22/25\n",
      "212/212 - 1s - loss: 0.6006 - accuracy: 0.8263 - val_loss: 1.4178 - val_accuracy: 0.6384 - 970ms/epoch - 5ms/step\n",
      "Epoch 23/25\n",
      "212/212 - 1s - loss: 0.5895 - accuracy: 0.8340 - val_loss: 1.4589 - val_accuracy: 0.6353 - 965ms/epoch - 5ms/step\n",
      "Epoch 24/25\n",
      "212/212 - 1s - loss: 0.5737 - accuracy: 0.8354 - val_loss: 1.4393 - val_accuracy: 0.6380 - 985ms/epoch - 5ms/step\n",
      "Epoch 25/25\n",
      "212/212 - 1s - loss: 0.5535 - accuracy: 0.8451 - val_loss: 1.4638 - val_accuracy: 0.6486 - 965ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_model_prediction(text):\n",
    "    text_representation = np.array(\n",
    "        pad(\n",
    "            tokenizer.texts_to_sequences(\n",
    "                [text]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prediction = list(model.predict(text_representation)[0])\n",
    "    column = prediction.index(max(prediction))\n",
    "    return column\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([model, get_model_prediction], open('model_eng.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "int"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
