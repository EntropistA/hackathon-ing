{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_input_data_eng.csv\").fillna(\"\")  # maybe drop?\n",
    "print(df.shape[0])\n",
    "\n",
    "x_columns = \"text\"\n",
    "y_columns = \"label_id\"\n",
    "x, y = df[x_columns], df[y_columns]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=4, stratify=y)\n",
    "\n",
    "training = pd.concat([x_train, y_train], axis=1)\n",
    "testing = pd.concat([x_test, y_test], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  label_id\n39                                                              3\n6956  invoice march nob tobacco industry national co...         1\n1953  political camfaign contribution request date f...         1\n3862  ace tlg lotresults fepdet crof verr tark esx p...        16\n1833  rjr s june sefeet nobyl dcclassi fi-afian to h...         7\n...                                                 ...       ...\n2122  ealshedeilier rqdrescrlellye hanufacturing cer...        17\n3934  newman-stein inc broadway job new york ny augu...        13\n6669  mar from slper arketing inc rjrpronotions clie...         6\n8931  principal investigatoaprogran dikecidy arthur ...        14\n6888        huduall yes lxd saga n kips meriuz bit luux         7\n\n[6760 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6956</th>\n      <td>invoice march nob tobacco industry national co...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1953</th>\n      <td>political camfaign contribution request date f...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3862</th>\n      <td>ace tlg lotresults fepdet crof verr tark esx p...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1833</th>\n      <td>rjr s june sefeet nobyl dcclassi fi-afian to h...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2122</th>\n      <td>ealshedeilier rqdrescrlellye hanufacturing cer...</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3934</th>\n      <td>newman-stein inc broadway job new york ny augu...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>6669</th>\n      <td>mar from slper arketing inc rjrpronotions clie...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8931</th>\n      <td>principal investigatoaprogran dikecidy arthur ...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6888</th>\n      <td>huduall yes lxd saga n kips meriuz bit luux</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>6760 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  label_id\n7453  sorillard memorandum max to mr goldbrenner fro...         8\n6972  e n w h mhl k hh m l j ul n m l a ve g w ie h ...         6\n1832  kantuety joumel o commets wanegrom dstt l tx g...         9\n6385  auz leon g cooperman chairman omege advisors i...        14\n7117                                      i h ie gglz l         9\n...                                                 ...       ...\n8833  clealtk qec sacramento bee weds smoking and vi...         9\n2276                                                            3\n8088  borriston laboratories inc sponsor lorillard i...        16\n1946  biographical sketch nane romaine r bruns posit...        14\n1522  jndinai ljs froms ostem erc sent moncdy june p...         2\n\n[2254 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7453</th>\n      <td>sorillard memorandum max to mr goldbrenner fro...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6972</th>\n      <td>e n w h mhl k hh m l j ul n m l a ve g w ie h ...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>kantuety joumel o commets wanegrom dstt l tx g...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6385</th>\n      <td>auz leon g cooperman chairman omege advisors i...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7117</th>\n      <td>i h ie gglz l</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8833</th>\n      <td>clealtk qec sacramento bee weds smoking and vi...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8088</th>\n      <td>borriston laboratories inc sponsor lorillard i...</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1946</th>\n      <td>biographical sketch nane romaine r bruns posit...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1522</th>\n      <td>jndinai ljs froms ostem erc sent moncdy june p...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2254 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sentences = x_train.to_list()\n",
    "\n",
    "LABEL_N = 21\n",
    "\n",
    "# First approach\n",
    "# LEARNING_RATE = 0.01\n",
    "# VOCAB_SIZE = 10_000\n",
    "# EMBEDDING_DIM = 16\n",
    "# DENSE_LAYER_COUNT = 128\n",
    "# max_length = 600\n",
    "# trunc_type='post'\n",
    "# padding_type='post'\n",
    "\n",
    "def pad(sequences):\n",
    "    return pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Optimized\n",
    "LEARNING_RATE = 0.002\n",
    "VOCAB_SIZE = 2_000\n",
    "EMBEDDING_DIM = 64\n",
    "DENSE_LAYER_COUNT = 128\n",
    "max_length = 400\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad(training_sequences)\n",
    "# training_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "testing_sentences = x_test.to_list()\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad(testing_sequences)\n",
    "# testing_padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_all_categories_columns(input_array: np.array):\n",
    "    result = np.zeros(shape=(input_array.shape[0], LABEL_N), dtype=int)\n",
    "    result[np.arange(0, input_array.shape[0]), input_array] = 1\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = create_all_categories_columns(np.array(y_train))\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = create_all_categories_columns(np.array(y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          128000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                2709      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,029\n",
      "Trainable params: 139,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(DENSE_LAYER_COUNT, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(LABEL_N, activation='softmax'),\n",
    "])\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "212/212 - 2s - loss: 2.5490 - accuracy: 0.1737 - val_loss: 2.3870 - val_accuracy: 0.2094 - 2s/epoch - 11ms/step\n",
      "Epoch 2/25\n",
      "212/212 - 1s - loss: 2.2161 - accuracy: 0.2735 - val_loss: 2.0777 - val_accuracy: 0.3381 - 1s/epoch - 5ms/step\n",
      "Epoch 3/25\n",
      "212/212 - 1s - loss: 1.9355 - accuracy: 0.3753 - val_loss: 1.8412 - val_accuracy: 0.4401 - 1s/epoch - 6ms/step\n",
      "Epoch 4/25\n",
      "212/212 - 1s - loss: 1.6957 - accuracy: 0.4799 - val_loss: 1.6394 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 5/25\n",
      "212/212 - 1s - loss: 1.4864 - accuracy: 0.5533 - val_loss: 1.5602 - val_accuracy: 0.5089 - 1s/epoch - 5ms/step\n",
      "Epoch 6/25\n",
      "212/212 - 1s - loss: 1.3431 - accuracy: 0.5957 - val_loss: 1.4183 - val_accuracy: 0.5856 - 1s/epoch - 6ms/step\n",
      "Epoch 7/25\n",
      "212/212 - 1s - loss: 1.2298 - accuracy: 0.6278 - val_loss: 1.3823 - val_accuracy: 0.5768 - 1s/epoch - 5ms/step\n",
      "Epoch 8/25\n",
      "212/212 - 1s - loss: 1.1398 - accuracy: 0.6571 - val_loss: 1.3181 - val_accuracy: 0.5843 - 1s/epoch - 6ms/step\n",
      "Epoch 9/25\n",
      "212/212 - 1s - loss: 1.0574 - accuracy: 0.6848 - val_loss: 1.3225 - val_accuracy: 0.6114 - 1s/epoch - 5ms/step\n",
      "Epoch 10/25\n",
      "212/212 - 1s - loss: 1.0059 - accuracy: 0.6999 - val_loss: 1.2710 - val_accuracy: 0.6220 - 1s/epoch - 6ms/step\n",
      "Epoch 11/25\n",
      "212/212 - 1s - loss: 0.9480 - accuracy: 0.7191 - val_loss: 1.2738 - val_accuracy: 0.6256 - 1s/epoch - 6ms/step\n",
      "Epoch 12/25\n",
      "212/212 - 1s - loss: 0.9043 - accuracy: 0.7345 - val_loss: 1.2715 - val_accuracy: 0.6260 - 1s/epoch - 5ms/step\n",
      "Epoch 13/25\n",
      "212/212 - 1s - loss: 0.8544 - accuracy: 0.7512 - val_loss: 1.2840 - val_accuracy: 0.6309 - 1s/epoch - 5ms/step\n",
      "Epoch 14/25\n",
      "212/212 - 1s - loss: 0.8207 - accuracy: 0.7574 - val_loss: 1.2801 - val_accuracy: 0.6304 - 1s/epoch - 5ms/step\n",
      "Epoch 15/25\n",
      "212/212 - 1s - loss: 0.7921 - accuracy: 0.7720 - val_loss: 1.2881 - val_accuracy: 0.6335 - 1s/epoch - 6ms/step\n",
      "Epoch 16/25\n",
      "212/212 - 1s - loss: 0.7550 - accuracy: 0.7808 - val_loss: 1.3236 - val_accuracy: 0.6398 - 1s/epoch - 5ms/step\n",
      "Epoch 17/25\n",
      "212/212 - 1s - loss: 0.7235 - accuracy: 0.7886 - val_loss: 1.3140 - val_accuracy: 0.6442 - 1s/epoch - 7ms/step\n",
      "Epoch 18/25\n",
      "212/212 - 1s - loss: 0.6915 - accuracy: 0.7997 - val_loss: 1.3312 - val_accuracy: 0.6358 - 1s/epoch - 6ms/step\n",
      "Epoch 19/25\n",
      "212/212 - 1s - loss: 0.6752 - accuracy: 0.8056 - val_loss: 1.3319 - val_accuracy: 0.6446 - 1s/epoch - 5ms/step\n",
      "Epoch 20/25\n",
      "212/212 - 1s - loss: 0.6514 - accuracy: 0.8089 - val_loss: 1.3944 - val_accuracy: 0.6340 - 1s/epoch - 5ms/step\n",
      "Epoch 21/25\n",
      "212/212 - 1s - loss: 0.6223 - accuracy: 0.8216 - val_loss: 1.4040 - val_accuracy: 0.6406 - 1s/epoch - 5ms/step\n",
      "Epoch 22/25\n",
      "212/212 - 1s - loss: 0.6071 - accuracy: 0.8283 - val_loss: 1.3945 - val_accuracy: 0.6393 - 1s/epoch - 5ms/step\n",
      "Epoch 23/25\n",
      "212/212 - 1s - loss: 0.5839 - accuracy: 0.8337 - val_loss: 1.4499 - val_accuracy: 0.6437 - 1s/epoch - 5ms/step\n",
      "Epoch 24/25\n",
      "212/212 - 1s - loss: 0.5638 - accuracy: 0.8383 - val_loss: 1.4498 - val_accuracy: 0.6380 - 1s/epoch - 5ms/step\n",
      "Epoch 25/25\n",
      "212/212 - 1s - loss: 0.5447 - accuracy: 0.8476 - val_loss: 1.4922 - val_accuracy: 0.6335 - 1s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_model_prediction(text):\n",
    "    text_representation = np.array(\n",
    "        pad(\n",
    "            tokenizer.texts_to_sequences(\n",
    "                [text]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prediction = list(model.predict(text_representation)[0])\n",
    "    column = prediction.index(max(prediction))\n",
    "    return column\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.eng\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.eng\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_eng\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tokenizer, open('tokenizer_eng.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
